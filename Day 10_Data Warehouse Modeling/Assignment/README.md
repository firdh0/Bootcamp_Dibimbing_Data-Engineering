# ğŸ“¦ DAY 10 - ASSIGNMENT

## ğŸš€ Project Overview

This project is an implementation of an **ETL (Extract, Transform, Load)** pipeline designed to process raw data, transform it into a structured format, and load it into a database. The pipeline is modular, allowing for easy customization and scalability.

> ğŸ›¢ï¸ **Database used**: PostgreSQL

> ğŸ§© **Connected via**: DBeaver (a powerful database management tool for developers and analysts)

## â­ Database Star Schema Design
![dim_category Table](./images/Schema%20Database-Star%20Schema.drawio.png)

## ğŸ“ Project Structure

The project is organized as follows:

```
.
â”œâ”€â”€ config/
â”‚   â””â”€â”€ db_config.yml          # ğŸ› ï¸ Configuration file for database connection
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # ğŸ“¥ Directory for raw data
â”‚   â”‚   â””â”€â”€ bbc_news.csv       # ğŸ“° Example raw data file
â”‚   â”œâ”€â”€ processed/
â”‚       â”œâ”€â”€ staging_data.parquet      # ğŸ—‚ï¸ Staging data file
â”‚       â””â”€â”€ transformed_data.parquet  # ğŸ”„ Transformed data file
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ etl/
â”‚   â”‚   â”œâ”€â”€ extract.py         # ğŸ“¤ Data extraction logic
â”‚   â”‚   â”œâ”€â”€ transform.py       # ğŸ§¹ Data transformation logic
â”‚   â”‚   â”œâ”€â”€ load.py            # ğŸ“¦ Data loading logic
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ logger.py          # ğŸ§¾ Logging utility
â”‚   â”‚   â”œâ”€â”€ db_connection.py   # ğŸ”Œ Database connection utility
â”‚   â”‚   â””â”€â”€ data_quality.py    # âœ… Data quality checks
â”‚   â”œâ”€â”€ logs/
â”‚   â”‚   â””â”€â”€ etl_pipeline.log   # ğŸ—’ï¸ Log file for ETL pipeline
â”œâ”€â”€ main.py                    # â–¶ï¸ Main script to run the ETL pipeline
â”œâ”€â”€ requirements.txt           # ğŸ“„ Python dependencies
â””â”€â”€ README.md                  # ğŸ“˜ Project documentation
```

## âœ¨ Features

* ğŸ“¤ **Data Extraction**: Reads raw data from CSV files and converts it into a staging format (Parquet).
* ğŸ§¹ **Data Transformation**: Cleans and processes the data, ensuring quality and consistency.
* ğŸ“¦ **Data Loading**: Loads the transformed data into **dimension and fact tables in a PostgreSQL database**.
* ğŸ§¾ **Logging**: Provides detailed logs for monitoring and debugging.

## âœ… Prerequisites

* ğŸ Python 3.10 or higher
* ğŸ˜ PostgreSQL database
* ğŸ–¥ï¸ DBeaver for managing and exploring the database
* ğŸ“¦ Required Python libraries (see `requirements.txt`)

## âš™ï¸ Installation

1. Clone the repository:

   ```bash
   git clone <repository-url>
   cd <repository-directory>
   ```

2. Set up a virtual environment:

   ```bash
   python -m venv venv
   venv\Scripts\activate  # On Windows
   ```

3. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

4. Configure the database connection in `config/db_config.yml`.

## ğŸ› ï¸ Usage

1. Place the raw data file (`bbc_news.csv`) in the `data/raw/` directory.
2. Run the ETL pipeline:

   ```bash
   python main.py
   ```

## ğŸ”„ ETL Pipeline Workflow

1. **Extract** ğŸ“¤: Reads raw data from `data/raw/bbc_news.csv` and saves it as `data/processed/staging_data.parquet`.
2. **Transform** ğŸ§¹: Processes the staging data, performs quality checks, and saves the transformed data as `data/processed/transformed_data.parquet`.
3. **Load** ğŸ“¦: Loads the transformed data into **dimension and fact tables** in a PostgreSQL database that is managed via **DBeaver**.

## ğŸ”§ Configuration

The database connection and other configurations are stored in `config/db_config.yml`. Update this file with your database credentials and other settings.

Example `db_config.yml`:

```yaml
database:
  host: "localhost"
  database: "your_database"
  user: "your_username"
  password: "your_password"
```

## ğŸ—’ï¸ Logging

Logs are saved in `scripts/logs/etl_pipeline.log`. The log file contains detailed information about the pipeline's execution, including errors and warnings.

## ğŸ“„ Dependencies

The required Python libraries are listed in `requirements.txt`. Install them using:

```bash
pip install -r requirements.txt
```

---

## ğŸ“Š Example Output

### âœ… 1. Data Loaded to PostgreSQL (via DBeaver)

ğŸ–¥ï¸ *Visualized in DBeaver*

**Table: `dim_category`**
![dim_category Table](./images/Screenshot%202025-05-05%20093308.png)

**Table: `fact_news`**
![dim_category Table](./images/Screenshot%202025-05-05%20093520.png)

---
